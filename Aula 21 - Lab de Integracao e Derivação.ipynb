{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integração\n",
    "\n",
    "Newton cotes: aproxima a função por um polinômio de newton e calcula a integral.\n",
    "\n",
    "### Trapézio: ###\n",
    "\n",
    "Aproxima a função f(x) por um trapézio (2 pontos)\n",
    "\n",
    "$$ I_1 = \\frac{h}{2}(y_0+y_1)$$\n",
    "\n",
    "### 1/3 de Simpson: ###\n",
    "\n",
    "Aproxima a função f(x) por uma parábola (3 pontos)\n",
    "\n",
    "$$ I_2 = \\frac{h}{3}(y_0+4y_1+y_2) $$\n",
    "\n",
    "\n",
    "### 3/8 de Simpson: ###\n",
    "\n",
    "Aproxima a função f(x) por uma hipérbole (4 pontos)\n",
    "\n",
    "$$ I_3 = \\frac{3h}{8}(y_0+3y_1+3y_2+y_3) $$\n",
    "\n",
    "Onde h é a distância entre dois pontos (equidistantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def trapezio(y,h):\n",
    "    i=(h/2)*sum(y)\n",
    "    return i\n",
    "\n",
    "def umtercosimpson(y,h):\n",
    "    i=(h/3)*(y[0]+4*y[1]+y[2])\n",
    "    return i\n",
    "\n",
    "def tresoitavos(y,h):\n",
    "    i=(3/8)*h*(y[0]+3*y[1]+3*y[2]+y[3])\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos testar?\n",
    "\n",
    "$$ \\int_0^1 e^{-x} dx$$\n",
    "\n",
    "$$ \\int_0^1 x^{2} dx$$\n",
    "\n",
    "$$ \\int_0^1 x^{3} dx$$\n",
    "\n",
    "$$ \\int_0^1 xe^{-x^2} dx$$\n",
    "\n",
    "$$ \\int_0^1 \\frac{1}{x^{2}+1} dx$$\n",
    "\n",
    "\n",
    "Faça os três métodos acima, e compare o erro absoluto e relativo com as integrais exatas (use o wolphram alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839397205857212\n",
      "0.6323336800036626\n",
      "0.6322155912488232\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "f = lambda x:np.exp(-x)\n",
    "\n",
    "def integra(f,a,b):\n",
    "    x = np.array([0,1])\n",
    "    y = f(x)\n",
    "    \n",
    "    print(trapezio(y,b))\n",
    "\n",
    "    x2=np.linspace(0,1,3)\n",
    "    y2=f(x2)\n",
    "    \n",
    "    print(umtercosimpson(y2,(b-a)/2))\n",
    "\n",
    "    x3=np.linspace(0,1,4)\n",
    "    y3=f(x3)\n",
    "    \n",
    "    print(tresoitavos(y3,(b-a)/3))\n",
    "    \n",
    "print(integra(f,0,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integração Composta\n",
    "\n",
    "### Trapézio Composto:\n",
    "\n",
    "$$ I_1 = \\frac{h}{2}(y_0+2y_1+2y_2+...+2y_{n-1}+y_n)$$\n",
    "\n",
    "Funciona para qualquer numero de pontos $>=2$.\n",
    "\n",
    "### 1/3 de Simpson\n",
    "\n",
    "$$ I_2 = \\frac{h}{3}(y_0+4y_1+2y_2+4y_3+2y_4+...+2y_{n-2}+4y_{n-1}+y_n) $$\n",
    "\n",
    "Funciona para $3+2n$ pontos, com $n>=0$\n",
    "\n",
    "### 3/8 de Simpson\n",
    "\n",
    "$$ I_3 = \\frac{3h}{8}(y_0+3y_1+3y_2+2y_3+...+2y_{n-3}+3y_{n-2}+3y_{n-1}+y_0)$$\n",
    "\n",
    "Funciona para $4+3n$ pontos, com $n>=0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezioc(y,h):\n",
    "    for i in range(len(y)):\n",
    "        if not(i==0 or i==len(y-1)):\n",
    "            y[i]*=2\n",
    "            \n",
    "    return (h/2)*sum(y)\n",
    "\n",
    "def umtercosimpsonc(y,h):\n",
    "    for i in range(len(y)):\n",
    "        if not(i==0 or i==len(y-1)):\n",
    "            if i%2 != 0:\n",
    "                y[i]*=4\n",
    "            else:\n",
    "                y[i]*=2\n",
    "    \n",
    "    return (h/3)*sum(y)\n",
    "\n",
    "def tresoitavosc(y,h):\n",
    "    ind=0\n",
    "    for i in range(len(y)):\n",
    "        if not(i==0 or i==len(y-1)):\n",
    "            ind+=1\n",
    "            if not(ind==3):\n",
    "                y[i]*=3\n",
    "            else:\n",
    "                y[i]*=2\n",
    "                ind=0\n",
    "    \n",
    "    return ((3*h)/8)*sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar? Use as integrais acima, mas com mais pontos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6339839104214203\n"
     ]
    }
   ],
   "source": [
    "f = lambda x:np.exp(-x)\n",
    "\n",
    "def integraC(f,a,b):\n",
    "    x = np.array([0,1])\n",
    "    y = f(x)\n",
    "    \n",
    "    print(trapezioc(y,b))\n",
    "\n",
    "    x2=np.linspace(0,1,3)\n",
    "    y2=f(x2)\n",
    "    \n",
    "    print(umtercosimpsonc(y2,(b-a)/2))\n",
    "\n",
    "    x3=np.linspace(0,1,4)\n",
    "    y3=f(x3)\n",
    "    \n",
    "    print(tresoitavosc(y3,(b-a)/3))\n",
    "\n",
    "n=100    \n",
    "x=np.linspace(0,1,n)\n",
    "y=f(x)\n",
    "print(trapezioc(y,(x[1]-x[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivação #\n",
    "\n",
    "Derivação, como sabemos bem, é uma técnica poderosa para inferir o comportamento de funçÕes e o relacionamento de fórmulas com os dados. Apesar da maior parte das equações ser diferenciável analiticamente, muitas vezes temos funções mais complexas geradas por dados de experimentos e afins que não são trivialmente diferenciáveis.\n",
    "\n",
    "Assim, é importante ter uma abordagem numérica para derivar __qualquer__ função.\n",
    "\n",
    "## Aproximação por diferenças finitas ##\n",
    "\n",
    "O método das diferenças finitas é utilizado quando se quer saber a derivada de _f(x)_ com relação a um valor/intervalo pequeno de _x_.\n",
    "\n",
    "Quando estas diferenças tem tamanho fixo, a diferença $\\Delta x$ é normalmente chamada de _h_, ou tamanho do passo.\n",
    "\n",
    "Ou seja, dada uma função e um intervalo [A,B], deseja-se saber a derivada da função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.6,'h')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "f = lambda x: x**2-2*x+2\n",
    "x = np.linspace(-1,1,100)\n",
    "y = f(x)\n",
    "\n",
    "xd = np.array([-0.3,0.3])\n",
    "yd =f(xd)\n",
    "\n",
    "plt.xticks(xd,[r'$x_i$', r'$x_{i+1}$'])\n",
    "plt.yticks(yd,[r'$f(x_i)$',r'$f(x_{i+1})$'])\n",
    "plt.xlim(-1.2,1.2)\n",
    "plt.ylim(0,5.2)\n",
    "\n",
    "plt.plot(x,y,linewidth=2)\n",
    "plt.plot(xd,yd,'r-')\n",
    "plt.plot([-1.2,xd[0]],[yd[0],yd[0]],'r--',linewidth=1)\n",
    "plt.plot([-1.2,xd[1]],[yd[1],yd[1]],'r--',linewidth=1)\n",
    "plt.plot([xd[0],xd[0]],[0,yd[0]],'r--',linewidth=1)\n",
    "plt.plot([xd[1],xd[1]],[0,yd[1]],'r--',linewidth=1)\n",
    "plt.plot([xd[0],xd[1]],[0.5,0.5],'b--',linewidth=1.5)\n",
    "plt.annotate('A',xy=(xd[0],yd[0]),xytext=(xd[0],yd[0]+0.1),color=\"black\",fontsize=12)\n",
    "plt.annotate('B',xy=(xd[1],yd[1]),xytext=(xd[1],yd[1]+0.1),color=\"black\",fontsize=12)\n",
    "plt.annotate('h',xy=((xd[0]+xd[1])/2,0.5),xytext=((xd[0]+xd[1])/2,0.6),color=\"black\",fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma mais simples de derivar é se achar a inclunação da reta AB, que é aproximadamente igual à da tangente da curva no meio do intervalo entre $x_i$ e $x_{i+1}$. Assim, quanto menor o intervalo, mais próximo do real é o valor obtido.\n",
    "\n",
    "A teoria por trás das diferenças definidas vem da expansão da série de Taylor de $f(x)$. A expansão para $f(x_{i+1})$ pode ser descrita como:\n",
    "\n",
    "$$ f(x_{i+1}) = f(x_i)+f'(x_i)h +\\frac{f''(x_i)}{2!}h^2+\\frac{f'''(x_i)}{3!}h^3+...$$\n",
    "\n",
    "Logo:\n",
    "\n",
    "$$ f'(x_{i}) = \\frac{f(x_{i+1})-f(x_i)}{h} - \\frac{f''(x_i)}{2!}h-\\frac{f'''(x_i)}{3!}h^2+...$$\n",
    "\n",
    "Como as segundas derivadas em diante são divididas por fatoriais e seu valor fica cada vez menor, elas podem ser omitidas, oque nos dá:\n",
    "\n",
    "$$ f'(x_{i}) = \\frac{f(x_{i+1})-f(x_i)}{h} + O(h) $$\n",
    "\n",
    "Esta fórmula é conhecida como _diferença dividida progressiva_, pois o segundo ponto é escolhido após $x_i$, ou seja, $h>0$. O(h) representa o erro advindo da truncagem da série de taylor (descartando termos com segundas derivadas em diante). Então na prática, a diferença dividida progressiva é:\n",
    "\n",
    "$$ f'(x_{i}) = \\frac{f(x_{i}+h)-f(x_i)}{h} $$\n",
    "\n",
    "Reaplicando a fórmula em $f'$, pode-se encontrar derivadas segundas, terceiras, etc:\n",
    "\n",
    "$$ f''(x_{i}) = \\frac{f(x_{i}+2h)-2f(x_{i}+h)+f(x_i)}{h^2} $$\n",
    "\n",
    "$$ f'''(x_{i}) = \\frac{f(x+3h)-3f(x_{i}+2h)+3f(x_{i}+h)-f(x_i)}{h^3}$$\n",
    "\n",
    "\n",
    "### Diferenças divididas regressivas ###\n",
    "\n",
    "De forma similar, podemos ter _diferenças divididas regressivas_, ou seja, quando o segundo ponto para gerar a reta tem um x anterior a $x_i$, ou seja, usa-se um $h<0$ ou multiplica-se h por -1:\n",
    "\n",
    "$$ f'(x_{i}) = \\frac{f(x_{i})-f(x_i-h)}{h} + O(h) $$\n",
    "\n",
    "$$ f''(x_{i}) = \\frac{f(x_{i})-2f(x_{i}-h)+f(x_i-2h)}{h^2} $$\n",
    "\n",
    "$$ f'''(x_{i}) = \\frac{f(x)-3f(x_{i}-h)+3f(x_{i}-2h)-f(x_i-3h)}{h^3}$$\n",
    "\n",
    "\n",
    "### Diferenças divididas centrais ###\n",
    "\n",
    "Diferenças progressivas ou regressivas podem ser utilizadas de acordo com o contexto, se há uma preocupação com o futuro ou o passado no resultado. Contudo, muitas vezes a preocupação é simplesmente a derivada em um dado ponto. Desta forma, o ideal seria colocar o ponto desejado __no meio__ do intervalo, ou seja, fazendo uma reta com os x no intervalo $[x-$h/2$,x+h/2]$.\n",
    "\n",
    "Desta forma, podemos calcular as diferenças divididas centrais como:\n",
    "\n",
    "$$ f'(x_{i}) = \\frac{f(x_{i}+h)-f(x_i-h)}{2h} $$\n",
    "\n",
    "De forma similar, podemos gerar as outras derivadas:\n",
    "\n",
    "$$ f''(x_{i}) = \\frac{f(x_{i}+h)-2f(x_{i})+f(x_i-h)}{h^2} $$\n",
    "\n",
    "$$ f'''(x_{i}) = \\frac{f(x+2h)-2f(x_{i}+h)+2f(x_{i}-h)-f(x_i-2h)}{2h^3}$$\n",
    "\n",
    "\n",
    "Complicado né? Vamos ver um exemplo para entender melhor:\n",
    "\n",
    "## Exemplo ##\n",
    "\n",
    "Vamos descobrir a primeira e a segunda derivada do polinomio abaixo no ponto 0.1:\n",
    "\n",
    "$f(x) = 0.1x^5 - 0.2x^3 + 0.1x - 0.2$\n",
    "\n",
    "Qual a solução analítica para a primeira e a segunda derivada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f'(0.1): 0.09405000000000001 f''(0.1): -0.118\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: 0.1*x**5 - 0.2*x**3 + 0.1*x - 0.2\n",
    "fd1 = lambda x:0.5*x**4 - 0.6*x**2 + 0.1\n",
    "fd2 = lambda x:2*x**3-1.2*x\n",
    "\n",
    "print(\"f'(0.1):\",fd1(0.1),\"f''(0.1):\",fd2(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos tentar aproximar estes valores numericamente utilizando diferenças definidas progressivas usando um h de 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1prog(f,x,h):\n",
    "    return (f(x+h)-f(x))/h\n",
    "\n",
    "d1prog(f,0.1,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente as diferenças regressivas e centrais para a primeira e segunda derivada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2prog(f,x,h):\n",
    "    return \n",
    "\n",
    "def d1reg(f,x,h):\n",
    "    return \n",
    "\n",
    "def d2reg(f,x,h):\n",
    "    return \n",
    "\n",
    "def d1cen(f,x,h):\n",
    "    return \n",
    "\n",
    "def d2cen(f,x,h):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora verifique qual dos três tem o menor erro para a primeira e segunda derivada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Derivada analitica:\",fd1(0.1),'Progressiva:',d1prog(f,0.1,0.05),\"Regressiva:\",d1reg(f,0.1,0.05),\"Central:\",d1cen(f,0.1,0.05))\n",
    "print(\"Derivada segunda analitica:\",fd2(0.1),'Progressiva:',d2prog(f,0.1,0.05),\"Regressiva:\",d2reg(f,0.1,0.05),\"Central:\",d2cen(f,0.1,0.05))\n",
    "\n",
    "\n",
    "xis = np.linspace(0,0.5,100)\n",
    "plt.plot(xis,f(xis))\n",
    "plt.plot(xis,fd1(xis),'r--')\n",
    "plt.plot(xis,d1prog(f,xis,0.05),'g--')\n",
    "plt.plot(xis,d1cen(f,xis,0.05),'y--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício ###\n",
    "\n",
    "Ache o valor da primeira e segunda derivada da função $f(x)=\\frac{2}{x^3+5}$ no ponto 1, com h=0.1, usando os três métodos e diga qual obteve o menor erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas e se eu não possuo a função $f$, como proceder? Ora, é simples: desde que você tenha pontos igualmente espaçados no eixo x (de preferência em um intervalo pequeno) você pode calcular as diferenças divididas diretamente!\n",
    "\n",
    "### Exemplo/Exercício ###\n",
    "\n",
    "Dada a tabela abaixo de valores de uma função _v_:\n",
    "\n",
    "|valor de $t_i$|0|60|120|180|240|300|\n",
    "|--------|-|-|-|-|-|-|-|-|\n",
    "|$v(t_i)$|0|0.0824|0.2747|0.6502|1.3851|3.229|\n",
    "\n",
    "1. Determine uma aproximação para v'(180) usando: i. Diferenças Progressivas ii. Regressivas iii. Centrais\n",
    "2. Como poderia proceder para determinar uma aproximação para v'(300)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
